# ğŸ§  ESNRegression - Echo State Network for Multivariate Regression

<div align="center">

**A high-performance Echo State Network library for real-time multivariate time
series prediction with incremental online learning**

[ğŸ“¦ JSR Package](https://jsr.io/@hviana/multivariate-regression) â€¢
[ğŸ’» GitHub](https://github.com/hviana/multivariate-regression) â€¢
[ğŸ“– Documentation](#-api-reference)

</div>

---

## ğŸ“‹ Table of Contents

- [âœ¨ Features](#-features)
- [ğŸš€ Quick Start](#-quick-start)
- [ğŸ“š Core Concepts](#-core-concepts)
  - [Echo State Networks](#-echo-state-networks-esn)
  - [Reservoir Computing](#-reservoir-computing)
  - [RLS Online Learning](#-rls-online-learning)
  - [Welford Normalization](#-welford-normalization)
- [âš™ï¸ Configuration Parameters](#ï¸-configuration-parameters)
  - [Reservoir Parameters](#reservoir-parameters)
  - [Training Parameters](#training-parameters)
  - [Normalization & Robustness](#normalization--robustness)
  - [Prediction Parameters](#prediction-parameters)
- [ğŸ¯ Parameter Optimization Guide](#-parameter-optimization-guide)
- [ğŸ“– API Reference](#-api-reference)
- [ğŸ’¡ Examples](#-examples)
- [ğŸ—ï¸ Architecture](#ï¸-architecture)
- [âš¡ Performance Tips](#-performance-tips)
- [ğŸ”§ Troubleshooting](#-troubleshooting)
- [ğŸ“„ License](#-license)

---

## âœ¨ Features

<table>
<tr>
<td width="50%">

### ğŸ¯ Core Capabilities

- **ğŸ”„ Online Learning** - Incremental RLS training, no batching required
- **ğŸ“ˆ Multi-step Prediction** - Direct or recursive multi-horizon forecasting
- **ğŸ›ï¸ Multivariate** - Handle multiple input features and output targets
- **âš¡ High Performance** - Zero-allocation hot paths with arena allocators

</td>
<td width="50%">

### ğŸ›¡ï¸ Robustness Features

- **ğŸ“Š Auto-normalization** - Welford's algorithm for streaming statistics
- **ğŸšï¸ Outlier Handling** - Automatic sample downweighting
- **ğŸ“‰ Uncertainty Quantification** - Confidence bounds on predictions
- **ğŸ’¾ Serialization** - Save/load model state

</td>
</tr>
</table>

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        ESNRegression Architecture                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚   Input Data â”€â”€â”¬â”€â”€â–º Welford Normalizer â”€â”€â–º ESN Reservoir â”€â”€â”               â”‚
â”‚                â”‚                              (Fixed)       â”‚               â”‚
â”‚                â”‚                                            â–¼               â”‚
â”‚                â””â”€â”€â–º Ring Buffer             Extended State: [r; x; 1]       â”‚
â”‚                     (History)                               â”‚               â”‚
â”‚                                                             â–¼               â”‚
â”‚   Target â”€â”€â”€â”€â”€â”€â–º RLS Optimizer â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€ Linear Readout â”€â”€â”˜               â”‚
â”‚                       â”‚                    (Trainable)                      â”‚
â”‚                       â–¼                                                     â”‚
â”‚               Updated Weights â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Predictions                       â”‚
â”‚                                           + Confidence                      â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Quick Start

### Installation

```typescript
import { ESNRegression } from "jsr:@hviana/multivariate-regression";
```

### Basic Usage

```typescript
// 1ï¸âƒ£ Create model
const model = new ESNRegression({
  maxFutureSteps: 5, // Predict up to 5 steps ahead
  reservoirSize: 256, // 256 reservoir neurons
  spectralRadius: 0.9, // Edge of chaos dynamics
});

// 2ï¸âƒ£ Train online (streaming data)
for (const sample of dataStream) {
  const result = model.fitOnline({
    xCoordinates: [sample.features], // [[f1, f2, f3, ...]]
    yCoordinates: [sample.targets], // [[t1, t2, ...]]
  });

  console.log(`ğŸ“Š Loss: ${result.averageLoss.toFixed(4)}`);
}

// 3ï¸âƒ£ Predict future steps
const prediction = model.predict(3); // 3 steps ahead
console.log("ğŸ”® Predictions:", prediction.predictions);
console.log("ğŸ“ˆ Confidence:", prediction.confidence);
console.log("ğŸ“‰ Lower bounds:", prediction.lowerBounds);
console.log("ğŸ“ˆ Upper bounds:", prediction.upperBounds);
```

---

## ğŸ“š Core Concepts

### ğŸŒŠ Echo State Networks (ESN)

Echo State Networks are a type of recurrent neural network where:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          ESN Architecture                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                            â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚    â”‚  Input  â”‚â”€â”€Winâ”€â–ºâ”‚         RESERVOIR (Fixed)           â”‚               â”‚
â”‚    â”‚   x_t   â”‚       â”‚  â”Œâ”€â”€â”€â” â”Œâ”€â”€â”€â” â”Œâ”€â”€â”€â” â”Œâ”€â”€â”€â” â”Œâ”€â”€â”€â”     â”‚               â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚  â”‚ â—‹ â”‚â”€â”‚ â—‹ â”‚â”€â”‚ â—‹ â”‚â”€â”‚ â—‹ â”‚â”€â”‚ â—‹ â”‚     â”‚               â”‚
â”‚                      â”‚  â””â”€â”¬â”€â”˜ â””â”€â”¬â”€â”˜ â””â”€â”¬â”€â”˜ â””â”€â”¬â”€â”˜ â””â”€â”¬â”€â”˜     â”‚               â”‚
â”‚                      â”‚    â”‚     â”‚     â”‚     â”‚     â”‚       â”‚               â”‚
â”‚                      â”‚  â”Œâ”€â–¼â”€â” â”Œâ”€â–¼â”€â” â”Œâ”€â–¼â”€â” â”Œâ”€â–¼â”€â” â”Œâ”€â–¼â”€â”     â”‚               â”‚
â”‚                      â”‚  â”‚ â—‹ â”‚â”€â”‚ â—‹ â”‚â”€â”‚ â—‹ â”‚â”€â”‚ â—‹ â”‚â”€â”‚ â—‹ â”‚     â”‚               â”‚
â”‚                      â”‚  â””â”€â”€â”€â”˜ â””â”€â”€â”€â”˜ â””â”€â”€â”€â”˜ â””â”€â”€â”€â”˜ â””â”€â”€â”€â”˜     â”‚               â”‚
â”‚                      â”‚         Recurrent connections (W)   â”‚               â”‚
â”‚                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                                        â”‚ r_t (reservoir state)             â”‚
â”‚                                        â–¼                                   â”‚
â”‚                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚                              â”‚  LINEAR READOUT â”‚                           â”‚
â”‚                              â”‚   (Trainable)   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Output y_t      â”‚
â”‚                              â”‚    Wout Ã— z     â”‚                           â”‚
â”‚                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â”‚                                                                            â”‚
â”‚    Key Insight: Only Wout is trained! Reservoir provides rich dynamics.   â”‚
â”‚                                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**The "Echo State Property"**: Past inputs create "echoes" that gradually fade
in the reservoir state, allowing the network to process temporal sequences.

#### State Update Equation

$$r_t = (1 - \alpha) \cdot r_{t-1} + \alpha \cdot \text{tanh}(W_{in} \cdot x_t + W \cdot r_{t-1} + b)$$

Where:

- $r_t$ = reservoir state at time $t$
- $\alpha$ = leak rate (controls memory/responsiveness trade-off)
- $W_{in}$ = input weight matrix (fixed)
- $W$ = reservoir weight matrix (fixed, scaled to spectral radius)
- $b$ = bias vector (fixed)

---

### ğŸ’¡ Reservoir Computing

The key insight of reservoir computing is **separation of concerns**:

| Component                       | Trained?   | Purpose                                             |
| ------------------------------- | ---------- | --------------------------------------------------- |
| **Input Weights ($W_{in}$)**    | âŒ Fixed   | Project input into high-dimensional reservoir space |
| **Reservoir Weights ($W$)**     | âŒ Fixed   | Create rich, nonlinear dynamics with memory         |
| **Readout Weights ($W_{out}$)** | âœ… Trained | Learn task-specific mapping from reservoir state    |

```
Input Space (low-dim) â”€â”€â–º Reservoir Space (high-dim) â”€â”€â–º Output Space
     n features              m neurons >> n              k targets
                                  â”‚
                     Nonlinear transformation
                     with temporal memory
```

**Benefits:**

- ğŸš€ Fast training (only linear readout)
- ğŸ“ˆ Universal approximation capability
- â±ï¸ Natural handling of temporal dependencies
- ğŸ’¾ Online/incremental learning friendly

---

### ğŸ“ RLS Online Learning

**Recursive Least Squares (RLS)** enables efficient online weight updates
without storing historical data.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        RLS Update Algorithm                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  For each new sample (z_t, y_t):                                       â”‚
â”‚                                                                         â”‚
â”‚  1. Compute Kalman gain:                                                â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚     â”‚  k_t = P_{t-1} Â· z_t / (Î» + z_t^T Â· P_{t-1} Â· z_t)          â”‚    â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                         â”‚
â”‚  2. Update weights:                                                     â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚     â”‚  W_t = W_{t-1} + k_t Â· (y_t - W_{t-1} Â· z_t)^T              â”‚    â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                         â”‚
â”‚  3. Update inverse correlation matrix:                                  â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚     â”‚  P_t = (P_{t-1} - k_t Â· z_t^T Â· P_{t-1}) / Î»                â”‚    â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                         â”‚
â”‚  Where:                                                                 â”‚
â”‚    Î» = forgetting factor (0.99-0.9999)                                 â”‚
â”‚    P = inverse correlation matrix                                       â”‚
â”‚    k = Kalman gain vector                                               â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Parameters:**

- **Î» (rlsLambda)**: Forgetting factor - lower values adapt faster but may be
  noisier
- **Î´ (rlsDelta)**: Initial P scaling - affects early learning stability

---

### ğŸ“Š Welford Normalization

The library uses **Welford's online algorithm** for numerically stable streaming
statistics:

```typescript
// Welford's Algorithm (internal implementation)
for each new sample x:
    n += 1
    delta = x - mean
    mean += delta / n
    delta2 = x - mean
    M2 += delta * delta2

variance = M2 / (n - 1)
std = sqrt(variance)
```

**Advantages:**

- âœ… Single-pass computation
- âœ… Numerically stable (no catastrophic cancellation)
- âœ… Memory efficient (only stores running stats)
- âœ… Warmup period before activation

---

## âš™ï¸ Configuration Parameters

### ğŸ“Š Complete Parameter Reference

```typescript
interface ESNRegressionConfig {
  // Reservoir Architecture
  maxSequenceLength?: number; // Default: 64
  maxFutureSteps?: number; // Default: 1
  reservoirSize?: number; // Default: 256
  spectralRadius?: number; // Default: 0.9
  leakRate?: number; // Default: 0.3
  inputScale?: number; // Default: 1.0
  biasScale?: number; // Default: 0.1
  reservoirSparsity?: number; // Default: 0.9
  inputSparsity?: number; // Default: 0.0
  activation?: "tanh" | "relu"; // Default: "tanh"

  // Readout Configuration
  useInputInReadout?: boolean; // Default: true
  useBiasInReadout?: boolean; // Default: true
  useDirectMultiHorizon?: boolean; // Default: true

  // RLS Training
  readoutTraining?: "rls"; // Default: "rls"
  rlsLambda?: number; // Default: 0.999
  rlsDelta?: number; // Default: 1.0
  l2Lambda?: number; // Default: 0.0001
  gradientClipNorm?: number; // Default: 1.0

  // Normalization
  normalizationEpsilon?: number; // Default: 1e-8
  normalizationWarmup?: number; // Default: 10

  // Robustness
  outlierThreshold?: number; // Default: 3.0
  outlierMinWeight?: number; // Default: 0.1

  // Uncertainty
  residualWindowSize?: number; // Default: 100
  uncertaintyMultiplier?: number; // Default: 1.96

  // General
  epsilon?: number; // Default: 1e-8
  weightInitScale?: number; // Default: 0.1
  seed?: number; // Default: 42
  verbose?: boolean; // Default: false
}
```

---

### Reservoir Parameters

#### `reservoirSize`

**Default: `256`** | Range: `[32, 4096]`

The number of neurons in the reservoir. Larger reservoirs can capture more
complex patterns but require more computation.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              reservoirSize Impact                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                â”‚
â”‚  Small (32-64)     â”‚  Medium (128-512)   â”‚  Large (512-2048)  â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚  âœ… Fast           â”‚  âœ… Balanced         â”‚  âœ… High capacity   â”‚
â”‚  âœ… Low memory     â”‚  âœ… Most use cases   â”‚  âŒ Slow training   â”‚
â”‚  âŒ Limited        â”‚                      â”‚  âŒ High memory     â”‚
â”‚     capacity       â”‚                      â”‚  âŒ Overfitting     â”‚
â”‚                    â”‚                      â”‚     risk            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Optimization Guide:**

| Scenario                        | Recommended Size |
| ------------------------------- | ---------------- |
| Simple linear trends            | 32-64            |
| Moderate complexity             | 128-256          |
| Complex patterns, many features | 512-1024         |
| Very high-dimensional data      | 1024-2048        |

```typescript
// Simple time series
const simpleModel = new ESNRegression({ reservoirSize: 64 });

// Complex multivariate forecasting
const complexModel = new ESNRegression({ reservoirSize: 512 });
```

---

#### `spectralRadius`

**Default: `0.9`** | Range: `(0, 1.0]`

Controls the "memory" of the reservoir. The spectral radius is the largest
absolute eigenvalue of the reservoir weight matrix.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Spectral Radius Effects                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                        â”‚
â”‚   Ï â†’ 0.5          â”‚    Ï â†’ 0.9           â”‚    Ï â†’ 1.0               â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€       â”‚    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€        â”‚    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€            â”‚
â”‚                    â”‚                       â”‚                          â”‚
â”‚   Short memory     â”‚    Balanced          â”‚    Long memory           â”‚
â”‚   Fast decay       â”‚    "Edge of chaos"   â”‚    Risk of instability   â”‚
â”‚   Quick response   â”‚    Rich dynamics     â”‚    Slow adaptation       â”‚
â”‚                    â”‚                       â”‚                          â”‚
â”‚   Input â”€â—‹â”€â—‹â”€â—‹â”€â–º   â”‚    Input â”€â—‹â”€â—‹â”€â—‹â”€â—‹â”€â–º  â”‚    Input â”€â—‹â”€â—‹â”€â—‹â”€â—‹â”€â—‹â”€â—‹â”€â–º â”‚
â”‚                    â”‚                       â”‚                          â”‚
â”‚   Use for:         â”‚    Use for:           â”‚    Use for:             â”‚
â”‚   â€¢ Fast signals   â”‚    â€¢ Most cases       â”‚    â€¢ Very slow dynamics â”‚
â”‚   â€¢ Little memory  â”‚    â€¢ Time series      â”‚    â€¢ Long dependencies  â”‚
â”‚     needed         â”‚                       â”‚                          â”‚
â”‚                    â”‚                       â”‚                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Mathematical Insight:** $$\text{Memory} \propto \frac{1}{1 - \rho}$$

```typescript
// Fast-changing signals (e.g., high-frequency trading)
const fastModel = new ESNRegression({ spectralRadius: 0.7 });

// Standard time series forecasting
const standardModel = new ESNRegression({ spectralRadius: 0.9 });

// Very long-term dependencies (e.g., climate data)
const longMemoryModel = new ESNRegression({ spectralRadius: 0.99 });
```

---

#### `leakRate`

**Default: `0.3`** | Range: `(0, 1]`

Controls how quickly the reservoir state updates. Also known as the "leaky
integrator" parameter.

$$r_t = (1 - \alpha) \cdot r_{t-1} + \alpha \cdot f(...)$$

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Leak Rate Visualization                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚   Î± = 0.1 (slow)        Î± = 0.5 (medium)      Î± = 1.0 (fast)   â”‚
â”‚                                                                 â”‚
â”‚   State response        State response        State response    â”‚
â”‚   to input step:        to input step:        to input step:    â”‚
â”‚                                                                 â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚
â”‚   â”‚     â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚    â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€       â”‚   â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚
â”‚   â”‚    â•±                â”‚   â•±                 â”‚   â”‚             â”‚
â”‚   â”‚   â•±                 â”‚  â•±                  â”‚   â”‚             â”‚
â”‚   â”‚  â•±                  â”‚ â•±                   â”‚   â”‚             â”‚
â”‚   â”‚ â•±                   â”‚â•±                    â”‚  â”€â”˜             â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”‚
â”‚                                                                 â”‚
â”‚   Smooth, filtered      Balanced              Instant response  â”‚
â”‚   High inertia          Most use cases        No filtering      â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

| Î± Value | Effect                          | Use Case                     |
| ------- | ------------------------------- | ---------------------------- |
| 0.1-0.3 | Strong smoothing, slow response | Noisy data, stable forecasts |
| 0.3-0.7 | Balanced                        | General purpose              |
| 0.7-1.0 | Fast response, little smoothing | Fast-changing dynamics       |

```typescript
// Noisy sensor data
const smoothModel = new ESNRegression({ leakRate: 0.2 });

// Standard forecasting
const balancedModel = new ESNRegression({ leakRate: 0.3 });

// Fast signal tracking
const responsiveModel = new ESNRegression({ leakRate: 0.8 });
```

---

#### `reservoirSparsity`

**Default: `0.9`** | Range: `[0, 1)`

Fraction of reservoir weights that are zero. Sparse reservoirs are more
computationally efficient and can have better generalization.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Reservoir Sparsity Patterns                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚   sparsity = 0.0          sparsity = 0.9          sparsity = 0.99      â”‚
â”‚   (fully connected)       (typical)               (very sparse)         â”‚
â”‚                                                                         â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚   â”‚â– â– â– â– â– â– â– â– â– â– â– â– â”‚         â”‚â–  â–¡ â–¡ â–¡ â–  â–¡ â”‚         â”‚â–¡ â–¡ â–¡ â–¡ â–  â–¡ â”‚      â”‚
â”‚   â”‚â– â– â– â– â– â– â– â– â– â– â– â– â”‚         â”‚â–¡ â–  â–¡ â–¡ â–¡ â–¡ â”‚         â”‚â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â”‚      â”‚
â”‚   â”‚â– â– â– â– â– â– â– â– â– â– â– â– â”‚         â”‚â–¡ â–¡ â–¡ â–  â–¡ â–¡ â”‚         â”‚â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â”‚      â”‚
â”‚   â”‚â– â– â– â– â– â– â– â– â– â– â– â– â”‚         â”‚â–¡ â–¡ â–¡ â–¡ â–¡ â–  â”‚         â”‚â–¡ â–¡ â–¡ â–  â–¡ â–¡ â”‚      â”‚
â”‚   â”‚â– â– â– â– â– â– â– â– â– â– â– â– â”‚         â”‚â–  â–¡ â–  â–¡ â–¡ â–¡ â”‚         â”‚â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â”‚      â”‚
â”‚   â”‚â– â– â– â– â– â– â– â– â– â– â– â– â”‚         â”‚â–¡ â–¡ â–¡ â–¡ â–  â–¡ â”‚         â”‚â–¡ â–  â–¡ â–¡ â–¡ â–¡ â”‚      â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                                                                         â”‚
â”‚   Dense, slow             Balanced, efficient     Very efficient        â”‚
â”‚   May overfit             Recommended             Risk of disconnection â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

```typescript
// Efficiency-focused (embedded systems)
const efficientModel = new ESNRegression({ reservoirSparsity: 0.95 });

// Research/accuracy-focused
const denseModel = new ESNRegression({ reservoirSparsity: 0.8 });
```

---

#### `inputScale`

**Default: `1.0`** | Range: `(0, âˆ)`

Scaling factor for input weights. Controls how strongly inputs drive the
reservoir.

```typescript
// Weak input signal (when data is already normalized)
const weakInput = new ESNRegression({ inputScale: 0.5 });

// Strong input signal (when input variations are small)
const strongInput = new ESNRegression({ inputScale: 2.0 });
```

---

#### `activation`

**Default: `"tanh"`** | Options: `"tanh"` | `"relu"`

Activation function for reservoir neurons.

| Activation | Formula     | Properties                       |
| ---------- | ----------- | -------------------------------- |
| `tanh`     | $\tanh(x)$  | Bounded [-1,1], smooth, centered |
| `relu`     | $\max(0,x)$ | Unbounded, sparse activation     |

```typescript
// Standard (recommended for most cases)
const tanhModel = new ESNRegression({ activation: "tanh" });

// For positive outputs or sparse dynamics
const reluModel = new ESNRegression({ activation: "relu" });
```

---

### Training Parameters

#### `rlsLambda` (Forgetting Factor)

**Default: `0.999`** | Range: `(0, 1]`

Controls how quickly RLS "forgets" old samples. Critical for online learning.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    RLS Forgetting Factor (Î») Effects                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                            â”‚
â”‚   Î» = 0.99 (fast forgetting)                                              â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                           â”‚
â”‚   â€¢ Effective window: ~100 samples                                         â”‚
â”‚   â€¢ Quickly adapts to changes                                              â”‚
â”‚   â€¢ May be noisy/unstable                                                  â”‚
â”‚   â€¢ Use for: non-stationary data, concept drift                           â”‚
â”‚                                                                            â”‚
â”‚   Sample weights over time:                                                â”‚
â”‚   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  (recent samples dominate)            â”‚
â”‚                                                                            â”‚
â”‚   Î» = 0.999 (slow forgetting) [DEFAULT]                                   â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                         â”‚
â”‚   â€¢ Effective window: ~1000 samples                                        â”‚
â”‚   â€¢ Balanced adaptation                                                    â”‚
â”‚   â€¢ Stable learning                                                        â”‚
â”‚   â€¢ Use for: most applications                                             â”‚
â”‚                                                                            â”‚
â”‚   Sample weights over time:                                                â”‚
â”‚   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  (smooth decay)                        â”‚
â”‚                                                                            â”‚
â”‚   Î» = 0.9999 (very slow forgetting)                                       â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                          â”‚
â”‚   â€¢ Effective window: ~10000 samples                                       â”‚
â”‚   â€¢ Very stable                                                            â”‚
â”‚   â€¢ Slow to adapt                                                          â”‚
â”‚   â€¢ Use for: stationary data, long-term patterns                          â”‚
â”‚                                                                            â”‚
â”‚   Sample weights over time:                                                â”‚
â”‚   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  (nearly uniform)                      â”‚
â”‚                                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Effective memory formula:** $$N_{eff} \approx \frac{1}{1 - \lambda}$$

```typescript
// Fast adaptation (concept drift, non-stationary)
const adaptiveModel = new ESNRegression({ rlsLambda: 0.99 });

// Balanced (most use cases)
const balancedModel = new ESNRegression({ rlsLambda: 0.999 });

// High stability (stationary data)
const stableModel = new ESNRegression({ rlsLambda: 0.9999 });
```

---

#### `rlsDelta`

**Default: `1.0`** | Range: `(0, âˆ)`

Initial scaling for the RLS inverse correlation matrix P.

```typescript
// Default initialization
const model = new ESNRegression({ rlsDelta: 1.0 });

// More conservative start (smaller initial updates)
const conservativeModel = new ESNRegression({ rlsDelta: 0.1 });

// More aggressive start (larger initial updates)
const aggressiveModel = new ESNRegression({ rlsDelta: 10.0 });
```

---

#### `l2Lambda`

**Default: `0.0001`** | Range: `[0, âˆ)`

L2 regularization strength. Prevents weight explosion and improves
generalization.

$$W_{new} = W_{old} \cdot (1 - \lambda_{L2})$$

```typescript
// No regularization (rare)
const noRegModel = new ESNRegression({ l2Lambda: 0 });

// Light regularization (default)
const lightRegModel = new ESNRegression({ l2Lambda: 0.0001 });

// Strong regularization (small datasets, overfitting)
const strongRegModel = new ESNRegression({ l2Lambda: 0.01 });
```

---

### Normalization & Robustness

#### `normalizationWarmup`

**Default: `10`** | Range: `[1, âˆ)`

Number of samples before normalization activates. During warmup, statistics are
collected but not applied.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Normalization Warmup                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                â”‚
â”‚   Sample:  1  2  3  4  5  6  7  8  9  10  11  12  13  ...    â”‚
â”‚            â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                   WARMUP PHASE        ACTIVE NORMALIZATION     â”‚
â”‚            Collecting statistics      z = (x - Î¼) / Ïƒ          â”‚
â”‚                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

```typescript
// Quick warmup (stable, known data distribution)
const quickWarmup = new ESNRegression({ normalizationWarmup: 5 });

// Long warmup (uncertain distribution)
const longWarmup = new ESNRegression({ normalizationWarmup: 50 });
```

---

#### `outlierThreshold`

**Default: `3.0`** | Range: `(0, âˆ)`

Z-score threshold for outlier detection. Samples with prediction errors
exceeding this threshold are downweighted.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Outlier Downweighting                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                        â”‚
â”‚   Sample weight vs Error magnitude (z-score)                           â”‚
â”‚                                                                        â”‚
â”‚   Weight                                                               â”‚
â”‚   1.0 â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                              â”‚
â”‚       â”‚                â”‚                                               â”‚
â”‚       â”‚                â”‚                                               â”‚
â”‚   0.5 â”¤                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                   â”‚
â”‚       â”‚                           â”‚                                    â”‚
â”‚       â”‚                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚   0.1 â”¤ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚       â”‚                           â†‘                                    â”‚
â”‚   0.0 â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º  â”‚
â”‚       0        1        2        3        4        5       z-score    â”‚
â”‚                                   â”‚                                    â”‚
â”‚                        outlierThreshold                                â”‚
â”‚                                                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

```typescript
// Strict outlier detection
const strictModel = new ESNRegression({ outlierThreshold: 2.0 });

// Lenient (include more samples)
const lenientModel = new ESNRegression({ outlierThreshold: 4.0 });
```

---

#### `outlierMinWeight`

**Default: `0.1`** | Range: `(0, 1]`

Minimum weight for any sample. Even extreme outliers contribute this much.

```typescript
// Completely ignore extreme outliers
const ignoreOutliers = new ESNRegression({ outlierMinWeight: 0.01 });

// Keep more outlier contribution
const keepOutliers = new ESNRegression({ outlierMinWeight: 0.3 });
```

---

### Prediction Parameters

#### `maxFutureSteps`

**Default: `1`** | Range: `[1, âˆ)`

Maximum number of future time steps to predict.

```typescript
// Single-step prediction
const singleStep = new ESNRegression({ maxFutureSteps: 1 });

// Multi-step forecasting
const multiStep = new ESNRegression({ maxFutureSteps: 10 });
```

---

#### `useDirectMultiHorizon`

**Default: `true`**

Strategy for multi-step prediction:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Multi-Step Prediction Strategies                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                            â”‚
â”‚   DIRECT (useDirectMultiHorizon: true) [Recommended]                      â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                     â”‚
â”‚                                                                            â”‚
â”‚   One forward pass â†’ All horizons                                          â”‚
â”‚                                                                            â”‚
â”‚   Input â”€â”€â–º Reservoir â”€â”€â–º Readout â”€â”€â”¬â”€â”€â–º y_{t+1}                          â”‚
â”‚                                     â”œâ”€â”€â–º y_{t+2}                          â”‚
â”‚                                     â”œâ”€â”€â–º y_{t+3}                          â”‚
â”‚                                     â””â”€â”€â–º ...                               â”‚
â”‚                                                                            â”‚
â”‚   âœ… Single pass                                                           â”‚
â”‚   âœ… No error accumulation                                                 â”‚
â”‚   âŒ Larger output dimension                                               â”‚
â”‚                                                                            â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                            â”‚
â”‚   RECURSIVE (useDirectMultiHorizon: false)                                â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                â”‚
â”‚                                                                            â”‚
â”‚   Multiple passes, feeding predictions back                                â”‚
â”‚                                                                            â”‚
â”‚   Input â”€â”€â–º Reservoir â”€â”€â–º y_{t+1} â”€â”                                      â”‚
â”‚                                    â–¼                                       â”‚
â”‚                    [y_{t+1}] â”€â”€â–º Reservoir â”€â”€â–º y_{t+2} â”€â”                 â”‚
â”‚                                                         â–¼                  â”‚
â”‚                                         [y_{t+2}] â”€â”€â–º Reservoir â”€â”€â–º ...   â”‚
â”‚                                                                            â”‚
â”‚   âœ… Smaller model                                                         â”‚
â”‚   âŒ Error accumulation                                                    â”‚
â”‚   âŒ Multiple forward passes                                               â”‚
â”‚                                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

```typescript
// Direct multi-horizon (recommended)
const directModel = new ESNRegression({
  maxFutureSteps: 5,
  useDirectMultiHorizon: true,
});

// Recursive (smaller model, potential drift)
const recursiveModel = new ESNRegression({
  maxFutureSteps: 5,
  useDirectMultiHorizon: false,
});
```

---

#### `uncertaintyMultiplier`

**Default: `1.96`** | Range: `(0, âˆ)`

Multiplier for confidence interval computation. Default 1.96 gives ~95%
confidence intervals (assuming normality).

| Value | Confidence Level |
| ----- | ---------------- |
| 1.0   | ~68%             |
| 1.65  | ~90%             |
| 1.96  | ~95%             |
| 2.58  | ~99%             |

```typescript
// 90% confidence intervals
const ci90Model = new ESNRegression({ uncertaintyMultiplier: 1.65 });

// 99% confidence intervals
const ci99Model = new ESNRegression({ uncertaintyMultiplier: 2.58 });
```

---

## ğŸ¯ Parameter Optimization Guide

### Decision Flowchart

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Parameter Selection Flowchart                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚                         START                                               â”‚
â”‚                           â”‚                                                 â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                    â”‚
â”‚              â”‚  Data characteristics?   â”‚                                    â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                    â”‚
â”‚                           â”‚                                                 â”‚
â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                              â”‚
â”‚        â”‚                  â”‚                  â”‚                              â”‚
â”‚   â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”                          â”‚
â”‚   â”‚  Noisy  â”‚       â”‚ Moderate â”‚       â”‚  Clean  â”‚                          â”‚
â”‚   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                          â”‚
â”‚        â”‚                 â”‚                 â”‚                                â”‚
â”‚   leakRate: 0.2     leakRate: 0.3     leakRate: 0.5                        â”‚
â”‚   outlierThresh: 2.0 outlierThresh: 3.0 outlierThresh: 4.0                  â”‚
â”‚                           â”‚                                                 â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                    â”‚
â”‚              â”‚  Time scale of patterns? â”‚                                    â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                    â”‚
â”‚                           â”‚                                                 â”‚
â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                              â”‚
â”‚        â”‚                  â”‚                  â”‚                              â”‚
â”‚   â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”                          â”‚
â”‚   â”‚  Fast   â”‚       â”‚ Medium  â”‚       â”‚  Slow   â”‚                          â”‚
â”‚   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                          â”‚
â”‚        â”‚                 â”‚                 â”‚                                â”‚
â”‚   spectralRadius: 0.7  spectralRadius: 0.9  spectralRadius: 0.99            â”‚
â”‚   reservoirSize: 128   reservoirSize: 256   reservoirSize: 512              â”‚
â”‚                           â”‚                                                 â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                    â”‚
â”‚              â”‚  Data stationarity?     â”‚                                    â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                    â”‚
â”‚                           â”‚                                                 â”‚
â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                              â”‚
â”‚        â”‚                  â”‚                  â”‚                              â”‚
â”‚   â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”                          â”‚
â”‚   â”‚Changing â”‚       â”‚  Mildly â”‚       â”‚Stationaryâ”‚                          â”‚
â”‚   â”‚ (drift) â”‚       â”‚ varying â”‚       â”‚          â”‚                          â”‚
â”‚   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                          â”‚
â”‚        â”‚                 â”‚                 â”‚                                â”‚
â”‚   rlsLambda: 0.99   rlsLambda: 0.999   rlsLambda: 0.9999                   â”‚
â”‚                           â”‚                                                 â”‚
â”‚                           â–¼                                                 â”‚
â”‚                        DONE                                                 â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Preset Configurations

```typescript
// ğŸ“ˆ Stock/Financial Data
const financialModel = new ESNRegression({
  reservoirSize: 256,
  spectralRadius: 0.95,
  leakRate: 0.4,
  rlsLambda: 0.995, // Moderate adaptation
  outlierThreshold: 2.5, // Strict outlier handling
  maxFutureSteps: 5,
});

// ğŸŒ¡ï¸ Sensor/IoT Data
const sensorModel = new ESNRegression({
  reservoirSize: 128,
  spectralRadius: 0.85,
  leakRate: 0.2, // Smooth noisy readings
  rlsLambda: 0.999,
  normalizationWarmup: 20,
  outlierThreshold: 3.0,
});

// âš¡ Fast-Changing Signals
const fastSignalModel = new ESNRegression({
  reservoirSize: 128,
  spectralRadius: 0.7,
  leakRate: 0.8,
  rlsLambda: 0.99,
});

// ğŸŒ Long-Term Patterns (Climate, etc.)
const longTermModel = new ESNRegression({
  reservoirSize: 512,
  spectralRadius: 0.99,
  leakRate: 0.2,
  rlsLambda: 0.9999,
  maxFutureSteps: 30,
});

// ğŸš€ Low-Latency/Embedded
const embeddedModel = new ESNRegression({
  reservoirSize: 64,
  reservoirSparsity: 0.95,
  spectralRadius: 0.85,
  maxFutureSteps: 1,
});
```

---

## ğŸ“– API Reference

### `ESNRegression`

#### Constructor

```typescript
new ESNRegression(config?: ESNRegressionConfig)
```

Creates a new ESN regression model with the specified configuration.

---

#### `fitOnline(params)`

```typescript
fitOnline(params: {
  xCoordinates: number[][];  // [nSamples, nFeatures]
  yCoordinates: number[][];  // [nSamples, nTargets] or [nSamples, nTargets * maxFutureSteps]
}): FitResult
```

Train the model incrementally with new data samples.

**Returns:**

```typescript
interface FitResult {
  samplesProcessed: number; // Number of samples processed
  averageLoss: number; // Average MSE loss
  gradientNorm: number; // Update magnitude
  driftDetected: boolean; // Always false (placeholder)
  sampleWeight: number; // Last sample's weight (outlier-adjusted)
}
```

**Example:**

```typescript
const result = model.fitOnline({
  xCoordinates: [[1.0, 2.0, 3.0], [1.1, 2.1, 3.1]],
  yCoordinates: [[0.5, 0.6], [0.55, 0.65]],
});
console.log(`Loss: ${result.averageLoss}`);
```

---

#### `predict(futureSteps)`

```typescript
predict(futureSteps: number): PredictionResult
```

Generate predictions for future time steps.

**Parameters:**

- `futureSteps`: Number of steps ahead to predict (1 to maxFutureSteps)

**Returns:**

```typescript
interface PredictionResult {
  predictions: number[][]; // [step][target]
  lowerBounds: number[][]; // [step][target]
  upperBounds: number[][]; // [step][target]
  confidence: number; // 0.0 to 1.0
}
```

**Example:**

```typescript
const result = model.predict(3);

for (let step = 0; step < 3; step++) {
  console.log(`Step ${step + 1}:`);
  console.log(`  Predictions: ${result.predictions[step]}`);
  console.log(
    `  95% CI: [${result.lowerBounds[step]}, ${result.upperBounds[step]}]`,
  );
}
console.log(`Confidence: ${(result.confidence * 100).toFixed(1)}%`);
```

---

#### `getModelSummary()`

```typescript
getModelSummary(): ModelSummary
```

Get model architecture and state information.

**Returns:**

```typescript
interface ModelSummary {
  totalParameters: number;
  receptiveField: number;
  spectralRadius: number;
  reservoirSize: number;
  nFeatures: number;
  nTargets: number;
  maxSequenceLength: number;
  maxFutureSteps: number;
  sampleCount: number;
  useDirectMultiHorizon: boolean;
}
```

---

#### `getWeights()`

```typescript
getWeights(): WeightInfo
```

Get model weights for inspection or debugging.

---

#### `getNormalizationStats()`

```typescript
getNormalizationStats(): NormalizationStats
```

Get current normalization parameters.

---

#### `save()` / `load(json)`

```typescript
save(): string              // Returns JSON string
load(json: string): void    // Restores from JSON string
```

Serialize/deserialize model state.

**Example:**

```typescript
// Save model
const modelState = model.save();
localStorage.setItem("esn_model", modelState);

// Load model later
const savedState = localStorage.getItem("esn_model");
model.load(savedState);
```

---

#### `reset()`

```typescript
reset(): void
```

Reset model to initial state, clearing all training history.

---

## ğŸ’¡ Examples

### Example 1: Simple Time Series Prediction

```typescript
import { ESNRegression } from "jsr:@hviana/multivariate-regression";

// Generate synthetic sine wave data
function generateSineData(n: number): { x: number[][]; y: number[][] } {
  const x: number[][] = [];
  const y: number[][] = [];

  for (let i = 0; i < n; i++) {
    const t = i * 0.1;
    x.push([Math.sin(t), Math.cos(t)]);
    y.push([Math.sin(t + 0.1)]); // Predict next value
  }

  return { x, y };
}

// Create and train model
const model = new ESNRegression({
  reservoirSize: 100,
  maxFutureSteps: 1,
});

const { x, y } = generateSineData(1000);

// Train in batches
const batchSize = 100;
for (let i = 0; i < x.length; i += batchSize) {
  const result = model.fitOnline({
    xCoordinates: x.slice(i, i + batchSize),
    yCoordinates: y.slice(i, i + batchSize),
  });
  console.log(
    `Batch ${Math.floor(i / batchSize) + 1}: Loss = ${
      result.averageLoss.toFixed(6)
    }`,
  );
}

// Predict
const prediction = model.predict(1);
console.log("Next value prediction:", prediction.predictions[0]);
```

---

### Example 2: Multi-Feature, Multi-Target Forecasting

```typescript
import { ESNRegression } from "jsr:@hviana/multivariate-regression";

// Weather-like multivariate data
interface WeatherSample {
  features: number[]; // [temperature, humidity, pressure, wind_speed]
  targets: number[]; // [next_temp, next_humidity]
}

const model = new ESNRegression({
  reservoirSize: 256,
  maxFutureSteps: 6, // Predict 6 hours ahead
  useDirectMultiHorizon: true,
  spectralRadius: 0.95,
  leakRate: 0.3,
});

// Streaming training
async function* dataStream(): AsyncGenerator<WeatherSample> {
  // Your data source here
  yield { features: [20.5, 0.65, 1013.25, 5.2], targets: [20.8, 0.63] };
  // ...
}

for await (const sample of dataStream()) {
  const result = model.fitOnline({
    xCoordinates: [sample.features],
    yCoordinates: [sample.targets],
  });

  if (result.samplesProcessed % 100 === 0) {
    console.log(
      `Samples: ${model.getModelSummary().sampleCount}, Loss: ${
        result.averageLoss.toFixed(4)
      }`,
    );
  }
}

// 6-hour forecast
const forecast = model.predict(6);
for (let h = 0; h < 6; h++) {
  console.log(`Hour ${h + 1}:`);
  console.log(`  Temperature: ${forecast.predictions[h][0].toFixed(1)}Â°C`);
  console.log(`  Humidity: ${(forecast.predictions[h][1] * 100).toFixed(0)}%`);
  console.log(
    `  Confidence: Â±${
      (forecast.upperBounds[h][0] - forecast.predictions[h][0]).toFixed(1)
    }Â°C`,
  );
}
```

---

### Example 3: Model Persistence

```typescript
import { ESNRegression } from "jsr:@hviana/multivariate-regression";

// Create and train model
const model = new ESNRegression({ reservoirSize: 128 });

// ... training ...

// Save model
const savedModel = model.save();
await Deno.writeTextFile("model.json", savedModel);

// Later: Load model
const loadedJson = await Deno.readTextFile("model.json");
const restoredModel = new ESNRegression({ reservoirSize: 128 });
restoredModel.load(loadedJson);

// Continue training or predict
const prediction = restoredModel.predict(1);
```

---

### Example 4: Handling Concept Drift

```typescript
import { ESNRegression } from "jsr:@hviana/multivariate-regression";

// For non-stationary data that changes over time
const adaptiveModel = new ESNRegression({
  reservoirSize: 200,
  rlsLambda: 0.99, // Fast forgetting
  outlierThreshold: 2.5, // Strict outlier detection
  maxFutureSteps: 3,
});

// Monitor loss for drift detection
let recentLosses: number[] = [];
const windowSize = 50;

for (const sample of streamingData) {
  const result = adaptiveModel.fitOnline({
    xCoordinates: [sample.x],
    yCoordinates: [sample.y],
  });

  // Track recent losses
  recentLosses.push(result.averageLoss);
  if (recentLosses.length > windowSize) {
    recentLosses.shift();
  }

  // Detect drift via loss increase
  if (recentLosses.length === windowSize) {
    const oldLoss = recentLosses.slice(0, windowSize / 2).reduce((a, b) =>
      a + b
    ) / (windowSize / 2);
    const newLoss = recentLosses.slice(windowSize / 2).reduce((a, b) => a + b) /
      (windowSize / 2);

    if (newLoss > oldLoss * 2) {
      console.log("âš ï¸ Possible concept drift detected!");
    }
  }
}
```

---

## ğŸ—ï¸ Architecture

### Internal Components Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              ESNRegression Internal Architecture                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                              PUBLIC API                                      â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚  â”‚  â”‚  fitOnline()  â”‚  â”‚  predict()  â”‚  â”‚ save/load()  â”‚  â”‚ getModelSummaryâ”‚  â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚             â”‚                 â”‚                                                     â”‚
â”‚             â–¼                 â–¼                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                           CORE COMPONENTS                                    â”‚   â”‚
â”‚  â”‚                                                                              â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚   â”‚
â”‚  â”‚  â”‚  WelfordNormalizerâ”‚    â”‚              ESN Model                       â”‚    â”‚   â”‚
â”‚  â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚    â”‚   â”‚
â”‚  â”‚  â”‚  â€¢ Online mean    â”‚    â”‚  â”‚  ESN Reservoir                        â”‚  â”‚    â”‚   â”‚
â”‚  â”‚  â”‚  â€¢ Online std     â”‚â”€â”€â”€â–ºâ”‚  â”‚  â€¢ Win [rs Ã— nF]                      â”‚  â”‚    â”‚   â”‚
â”‚  â”‚  â”‚  â€¢ Z-score norm   â”‚    â”‚  â”‚  â€¢ W   [rs Ã— rs] (spectral scaled)   â”‚  â”‚    â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  â”‚  â€¢ bias [rs]                          â”‚  â”‚    â”‚   â”‚
â”‚  â”‚                          â”‚  â”‚  â€¢ state [rs] (leaky integrator)      â”‚  â”‚    â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚    â”‚   â”‚
â”‚  â”‚  â”‚   Ring Buffer    â”‚    â”‚                      â”‚                       â”‚    â”‚   â”‚
â”‚  â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚    â”‚                      â–¼                       â”‚    â”‚   â”‚
â”‚  â”‚  â”‚  â€¢ History store â”‚    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚    â”‚   â”‚
â”‚  â”‚  â”‚  â€¢ Window extractâ”‚    â”‚  â”‚  Linear Readout                       â”‚  â”‚    â”‚   â”‚
â”‚  â”‚  â”‚  â€¢ Circular FIFO â”‚    â”‚  â”‚  â€¢ Wout [output Ã— input]              â”‚  â”‚    â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  â”‚  â€¢ Extended state: z = [r; x; 1]      â”‚  â”‚    â”‚   â”‚
â”‚  â”‚                          â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚    â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚                      â”‚                       â”‚    â”‚   â”‚
â”‚  â”‚  â”‚  Residual Trackerâ”‚    â”‚                      â–¼                       â”‚    â”‚   â”‚
â”‚  â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚    â”‚   â”‚
â”‚  â”‚  â”‚  â€¢ Error stats   â”‚â—„â”€â”€â”€â”‚  â”‚  RLS Optimizer                        â”‚  â”‚    â”‚   â”‚
â”‚  â”‚  â”‚  â€¢ Uncertainty   â”‚    â”‚  â”‚  â€¢ P matrix [input Ã— input]           â”‚  â”‚    â”‚   â”‚
â”‚  â”‚  â”‚  â€¢ Confidence    â”‚    â”‚  â”‚  â€¢ Kalman gain                        â”‚  â”‚    â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  â”‚  â€¢ Sherman-Morrison updates           â”‚  â”‚    â”‚   â”‚
â”‚  â”‚                          â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚    â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚   â”‚
â”‚  â”‚  â”‚ OutlierDownweightâ”‚                                                        â”‚   â”‚
â”‚  â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                                                        â”‚   â”‚
â”‚  â”‚  â”‚  â€¢ Z-score check â”‚                                                        â”‚   â”‚
â”‚  â”‚  â”‚  â€¢ Sample weightsâ”‚                                                        â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                        MEMORY MANAGEMENT                                     â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚  â”‚  â”‚ TensorArena  â”‚  â”‚ BufferPool   â”‚  â”‚     TensorOps (zero-copy)        â”‚  â”‚   â”‚
â”‚  â”‚  â”‚ (params)     â”‚  â”‚ (scratch)    â”‚  â”‚  matvec, outer, dot, scale, etc. â”‚  â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âš¡ Performance Tips

### 1ï¸âƒ£ Memory Efficiency

```typescript
// âœ… Good: Process in batches
for (let i = 0; i < data.length; i += 100) {
  model.fitOnline({
    xCoordinates: data.slice(i, i + 100).map((d) => d.x),
    yCoordinates: data.slice(i, i + 100).map((d) => d.y),
  });
}

// âŒ Avoid: Single sample at a time (more overhead)
for (const sample of data) {
  model.fitOnline({ xCoordinates: [sample.x], yCoordinates: [sample.y] });
}
```

### 2ï¸âƒ£ Reservoir Size vs. Speed

```typescript
// Trade-off analysis
const benchmarks = [
  { size: 64, opsPerSec: 50000 },
  { size: 128, opsPerSec: 20000 },
  { size: 256, opsPerSec: 8000 },
  { size: 512, opsPerSec: 2500 },
];
// Choose based on your latency requirements
```

### 3ï¸âƒ£ Sparsity for Speed

```typescript
// High sparsity = fewer computations
const fastModel = new ESNRegression({
  reservoirSize: 512,
  reservoirSparsity: 0.95, // 95% sparse = 5% of weights active
});
```

### 4ï¸âƒ£ Reuse Prediction Results

```typescript
// âœ… Good: Single predict call
const result = model.predict(5);
for (let i = 0; i < 5; i++) {
  process(result.predictions[i]);
}

// âŒ Avoid: Multiple predict calls for same horizon
for (let i = 1; i <= 5; i++) {
  const result = model.predict(i); // Redundant computation
}
```

---

## ğŸ”§ Troubleshooting

### Common Issues

#### ğŸ”´ "Model not initialized" Error

```typescript
// Problem: Calling predict() before fitOnline()
const model = new ESNRegression();
model.predict(1); // âŒ Error!

// Solution: Train first
model.fitOnline({ xCoordinates: [[1, 2]], yCoordinates: [[3]] });
model.predict(1); // âœ… Works
```

#### ğŸ”´ High Loss / Poor Predictions

```typescript
// Check 1: Data normalization
console.log(model.getNormalizationStats());
// If stds are very large/small, data may have issues

// Check 2: Reservoir dynamics
const summary = model.getModelSummary();
console.log("Spectral radius:", summary.spectralRadius);
// Try adjusting spectralRadius if patterns are lost

// Check 3: Warmup period
if (summary.sampleCount < 100) {
  console.log("Need more training samples");
}
```

#### ğŸ”´ Numerical Instability (NaN/Inf)

```typescript
// Solution: Add regularization and clipping
const stableModel = new ESNRegression({
  l2Lambda: 0.001, // Stronger regularization
  gradientClipNorm: 0.5, // More aggressive clipping
  inputScale: 0.5, // Reduce input magnitude
});
```

#### ğŸ”´ Slow Training

```typescript
// Solution: Reduce reservoir size and increase sparsity
const fastModel = new ESNRegression({
  reservoirSize: 128, // Smaller reservoir
  reservoirSparsity: 0.95, // More sparse
  inputSparsity: 0.5, // Sparse input connections
});
```

---

## ğŸ“Š Comparison with Other Methods

| Method            | Online Learning | Multi-step | Memory Efficient | Setup Complexity |
| ----------------- | :-------------: | :--------: | :--------------: | :--------------: |
| **ESNRegression** |       âœ…        |     âœ…     |        âœ…        |       Low        |
| ARIMA             |       âŒ        |     âš ï¸     |        âœ…        |      Medium      |
| LSTM              |       âš ï¸        |     âœ…     |        âŒ        |       High       |
| Transformer       |       âŒ        |     âœ…     |        âŒ        |       High       |
| Prophet           |       âŒ        |     âœ…     |        âœ…        |       Low        |

---

## ğŸ“„ License

**MIT License** Â© 2025 [Henrique Emanoel Viana](https://github.com/hviana)

```
Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software...
```

---

<div align="center">

**[â¬† Back to Top](#-esnregression---echo-state-network-for-multivariate-regression)**

Made with â¤ï¸ by [Henrique Emanoel Viana](https://github.com/hviana)

</div>
